{
 "metadata": {
  "name": "",
  "signature": "sha256:e00be0d49fd3d6c8f77aedf6bdf06e263c227a78bf55161c81029bab26270efa"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy.matlib\n",
      "\n",
      "import nengo\n",
      "from nengo.spa import Vocabulary\n",
      "from nengo import spa\n",
      "from nengo.spa.utils import similarity\n",
      "from nengo_gui.ipython import IPythonViz\n",
      "from nengo.utils.functions import piecewise\n",
      "\n",
      "from tempfile import TemporaryFile\n",
      "#import nengo_spinnaker"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Parameters\n",
      "\n",
      "testorder = 1; #1 = forward, 2 = random\n",
      "\n",
      "n = 64   #200     # length of content vectors\n",
      "nc = n      # length of context vectors\n",
      "v = 10 #100     # vocabulary size\n",
      "rtype = 2   # representation type: 1 = Gaussian vectors, 2 = Walsh vectors\n",
      "ctype = 1   # context type: 1: similarity structure defined by csim; 2: Xuan-Choo style circular convolution from base\n",
      "sim = 0.3   # average similarity between content vectors\n",
      "csim = 0.5  # average similarity between context vectors\n",
      "noise = 0.0 * n  #noise added\n",
      "rsupp = 1.0    #strength of response suppression (as proportion of A)\n",
      "primacy = 0.9  #primacy gradient\n",
      "outputinterference = 0.05\n",
      "activation = 0.0\n",
      "ntrials = 1\n",
      "nreplic = 1 #100\n",
      "nsetsize = 5\n",
      "SSspc = 6\n",
      "\n",
      "#Readout and presentation time in ms\n",
      "readout_time = 250\n",
      "pres_time = 500\n",
      "sim_time = (pres_time + readout_time*nsetsize)\n",
      "\n",
      "rdt = readout_time/1000.0\n",
      "pt = pres_time/1000.0\n",
      "\n",
      "output_matrix = np.zeros((nreplic, ntrials, nsetsize+1, nsetsize))\n",
      "\n",
      "N_mem = 50  #No of neurons for wm\n",
      "N_conv = 100 #No of neurons for the convolutional network\n",
      "\n",
      "#Declaring empty position and item vectors \n",
      "Context = np.empty((nsetsize,nc))\n",
      "Content = np.empty((nsetsize,v))\n",
      "sel_content = np.empty((nsetsize,n))\n",
      "\n",
      "#no of dimensions = length of content/context vectors\n",
      "D = n\n",
      "\n",
      "# Change the seed of the rng to change the vocabulary\n",
      "rng = np.random.RandomState(3)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#gate_func = lambda t: int((t * 10) % 2)\n",
      "input_vec = 0\n",
      "\n",
      "def record_result(data, item_seq, trial): \n",
      "    #print \"item_seq: \", item_seq\n",
      "    match_list = list()\n",
      "    \n",
      "    for pos in range(nsetsize): \n",
      "        st = pres_time + readout_time*pos\n",
      "        et = st+readout_time-1\n",
      "        sub_data = data[st:et,:]\n",
      "        a = (np.sum(sub_data,0)/sub_data.shape[0]).tolist()\n",
      "        max_sim = max(a)\n",
      "        match_item = a.index(max_sim)     # match_item = [i for i, j in enumerate(a) if j == max_sim]\n",
      "        match_list.append(match_item)  \n",
      "        if match_item not in item_seq:\n",
      "            output_matrix[replic, trial, nsetsize, pos] = 1\n",
      "        else:\n",
      "            index = item_seq.index(match_item)      \n",
      "            output_matrix[replic, trial, index, pos] = 1\n",
      "    #print \"match list: \", match_list\n",
      "            \n",
      "\n",
      "def wm_input_func(t):\n",
      "    if t<pt:\n",
      "        return input_vec\n",
      "    else:\n",
      "        return 0\n",
      "\n",
      " \n",
      "def cue_input_func(t):\n",
      "    set_t = rdt*nsetsize\n",
      "        \n",
      "    if t <= pt:\n",
      "        return  vocab.parse('ZERO').v\n",
      "    \n",
      "    for i in range(1,nsetsize+1): \n",
      "        if t > (pt + rdt * (i-1)) and t <= (pt + rdt*i):   \n",
      "            return vocab.parse('POS%i' %(int(i-1))).v\n",
      "            break\n",
      "        \n",
      "\n",
      "def make_model(wm_vocab):\n",
      "    model = spa.SPA('Working_Memory')   \n",
      "    \n",
      "    pt = (pres_time/1000.0)\n",
      "    \n",
      "    with model: \n",
      "        model.config[nengo.Ensemble].neuron_type = nengo.LIFRate()\n",
      "        model.wm = spa.MemoryBlock(n_neurons=N_mem, dimensions=D, vocab=wm_vocab)\n",
      "        \n",
      "        #Generate the input to the memory\n",
      "        cue_node = nengo.Node(cue_input_func, label='Input Node')\n",
      "        \n",
      "        gate_node = nengo.Node(piecewise({0: 0, pt/2: 1, pt: 0}))\n",
      "        nengo.Connection(gate_node, model.wm.gate)\n",
      "        \n",
      "        wm_input = nengo.Node(output=wm_input_func, size_out=D)\n",
      "        nengo.Connection(wm_input, model.wm.input)\n",
      "        \n",
      "        # computing R' convolved with A* (correct answer)\n",
      "        cconv = nengo.networks.CircularConvolution(n_neurons=N_conv, dimensions=D, invert_b=True)\n",
      "        nengo.Connection(model.wm.output, cconv.A)\n",
      "        nengo.Connection(cue_node, cconv.B)\n",
      "        #nengo.Connection(cconv.output, output)\n",
      "        \n",
      "        # Model probes\n",
      "        p_wmin = nengo.Probe(wm_input)\n",
      "        p_cue = nengo.Probe(cue_node)\n",
      "        p_wmout = nengo.Probe(model.wm.output, synapse=0.01)\n",
      "        p_output = nengo.Probe(cconv.output, synapse=0.01)\n",
      "    \n",
      "    return model, [p_wmin, p_cue, p_wmout, p_output]\n",
      "\n",
      "def run_model(model):\n",
      "    sim = nengo.Simulator(model)\n",
      "    #sim = nengo_spinnaker.Simulator(model)\n",
      "    sim.run(sim_time/1000.0)\n",
      "    return sim\n",
      "\n",
      "def plot_figures(sim, p, wm_vocab):\n",
      "    plt.figure(figsize=(12, 12));\n",
      "    \n",
      "    plt.subplot(4, 1, 1)\n",
      "    plt.plot(sim.trange(), similarity(sim.data[p[0]], vocab))\n",
      "    legend = plt.legend(vocab.keys, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0, fontsize=9)\n",
      "    plt.title(\"WM Input\")\n",
      "   \n",
      "    plt.subplot(4, 1, 2)\n",
      "    plt.plot(sim.trange(), similarity(sim.data[p[2]], vocab))\n",
      "    plt.title(\"WM Output\")\n",
      "    \n",
      "    plt.subplot(4, 1, 3)\n",
      "    plt.plot(sim.trange(), similarity(sim.data[p[1]], vocab))\n",
      "    plt.title(\"Cue Input\") \n",
      "    \n",
      "    plt.subplot(4, 1, 4)\n",
      "    plt.plot(sim.trange(), similarity(sim.data[p[3]], wm_vocab))\n",
      "    plt.title(\"Output/Answer\")\n",
      "    plt.legend(wm_vocab.keys, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0, fontsize=9)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#for replic = 1:nreplic\n",
      "for replic in range(nreplic):\n",
      "    \n",
      "    if rtype == 1:\n",
      "        Cntproto = np.random.randn(1,n) * 1/np.sqrt(n);\n",
      "        Newcontent = np.random.randn(v,n) * 1/np.sqrt(n);\n",
      "        Flip = np.random.rand(v,n) > np.sqrt(sim)   #sqrt(sim), so that the vectors derived from the common prototype have similarity = sim\n",
      "        Content = np.multiply((1-Flip) , np.matlib.repmat(Cntproto, v, 1)) + np.multiply (Flip , Newcontent)\n",
      "        \n",
      "        # sequential contexts\n",
      "        if ctype == 1:\n",
      "            Context[0,:] = np.random.randn(1,nc) * 1/sqrt(nc);\n",
      "            #for pos = 2:nsetsize:\n",
      "            for pos in range(1,nsetsize):\n",
      "                keep = np.random.rand(1,nc) < csim\n",
      "                Context[pos,:] = np.multiply (keep , Context[pos-1,:]) + np.multiply((1-keep) , (np.random.randn(1,nc) * 1/np.sqrt(nc)))\n",
      "        \n",
      "        \n",
      "        # sequential context, Xuan-Choo style\n",
      "        if ctype == 2:\n",
      "            base = randn(1,nc) * 1/sqrt(nc)\n",
      "            Context[0,:] = base\n",
      "            #for pos = 2:nsetsize\n",
      "            for pos in range(1,nsetsize):\n",
      "                Context[pos,:] = Circconv2(Context[pos-1,:], base, n)\n",
      "                Context[pos,:] = np.divide(Context[pos,:], np.linalg.norm(Context[pos,:])) #normalize! \n",
      "        \n",
      "        \n",
      "    if rtype == 2:\n",
      "        Cntproto = np.divide(np.sign(np.random.rand(1,n) - 0.5), np.sqrt(n))\n",
      "        Newcontent = np.sign(np.random.rand(v,n) - 0.5) / np.sqrt(n)\n",
      "        Flip = np.random.rand(v,n) > np.sqrt(sim)   #sqrt(sim), so that the vectors derived from the common prototype have similarity = sim\n",
      "        Content = np.multiply((1-Flip) , np.matlib.repmat(Cntproto, v, 1)) + np.multiply(Flip , Newcontent)\n",
      "        \n",
      "        \n",
      "        #sequential contexts\n",
      "        if ctype == 1:\n",
      "            Context[0,:] = np.divide(np.sign(np.random.rand(1,nc) - 0.5), np.sqrt(nc))\n",
      "            #for pos = 2:nsetsize\n",
      "            for pos in range(1,nsetsize):\n",
      "                keep = np.random.rand(1,nc) < csim\n",
      "                Context[pos,:] = np.multiply(keep , Context[pos-1,:]) \\\n",
      "                                + np.multiply((1-keep) , np.divide((np.sign(np.random.rand(1,nc) - 0.5)), np.sqrt(nc))) \n",
      "                \n",
      "\n",
      "        if ctype == 2:\n",
      "            base = np.divide(np.sign(np.random.rand(1,n) - 0.5) , np.sqrt(n))\n",
      "            Context[0,:] = base\n",
      "            #or pos = 2:nsetsize\n",
      "            for pos in range(1,nsetsize):\n",
      "                Context[pos,:] = Circconv2(Context[pos-1,:], base, n)\n",
      "                Context[pos,:] = np.divide(Context[pos,:], np.linalg.norm(Context[pos,:])) #normalize!   \n",
      "                \n",
      "        \n",
      "    #print \"Context: \", Context.shape\n",
      "    #print Context\n",
      "    #print \"Content: \", Content.shape\n",
      "    #print Content   \n",
      "    #print \"Content:\\n \", sel_content  \n",
      "    \n",
      "    vocab = Vocabulary(dimensions=D, rng=rng, max_similarity=0.05)  \n",
      "    # ----------------------------------------------------------------------\n",
      "\n",
      "    #Add the contexts (positions) to the vocabulary\n",
      "    for pos in range(nsetsize):\n",
      "        vocab.add('POS%i' %pos, Context[pos,:])\n",
      "\n",
      "    # ------------------------------------------------------------------------ \n",
      "\n",
      "    #Add the contents(items) to the vocabulary\n",
      "    for item in range(v): \n",
      "        vocab.add('ITEM%i' %item, Content[item,:])   \n",
      "\n",
      "    # ------------------------------------------------------------------------- \n",
      "        \n",
      "    # Create a sub-vocab for a subject\n",
      "    list_items = [\"ITEM%i\" % i for i in range(v)]\n",
      "    wm_vocab = vocab.create_subset(list_items) \n",
      "\n",
      "    \n",
      "    for trial in range(ntrials):\n",
      "        List = numpy.random.permutation(v)         \n",
      "        item_seq = list()\n",
      "        input_vec = 0\n",
      "        \n",
      "        #Add the convolved representations to the vocabulary\n",
      "        for element in range(nsetsize): \n",
      "            item = List[element]\n",
      "            item_seq.append(item)     #build a sequence list\n",
      "            content = Content[item,:]\n",
      "            sel_content[element,:] = content\n",
      "            vocab.parse(('POS%i * ITEM%i' %(element, item)))\n",
      "            input_vec += vocab.parse(('POS%i * ITEM%i' %(element, item))).v\n",
      "            \n",
      "        #Build and Run the model, plot results\n",
      "        nengo_model, probes = make_model(wm_vocab)\n",
      "        nengo_sim = run_model(nengo_model)\n",
      "        #plot_figures(nengo_sim, probes, wm_vocab) \n",
      "        data = similarity(nengo_sim.data[probes[3]], wm_vocab)\n",
      " \n",
      "        record_result(data, item_seq, trial)  \n",
      "        \n",
      "    \n",
      "        \n",
      "\n",
      "#print \"output_matrix: \\n\", output_matrix        \n",
      "#mIOX = np.mean(output_matrix, 0)   #computing the mean matrix from all the trials\n",
      "#rIOX = mIOX[:nsetsize,:]   #take out the last row for extralist intrusions\n",
      "#spc = np.diag(rIOX)        #serial position curve\n",
      "\n",
      "#transpos = np.zeros((1,setsize-1))\n",
      "#transpos = [None]*(nsetsize-1)\n",
      "\n",
      "#for tr in range(1,nsetsize):\n",
      "#    transpos[tr-1] = np.mean((np.diag(rIOX,tr) + np.diag(rIOX,-tr))/2)\n",
      "\n",
      "#plt.figure(figsize=(12, 12));\n",
      "#plt.subplot(2, 1, 1)\n",
      "#plt.plot(list(range(1,nsetsize+1)), spc)\n",
      "#plt.xlabel(\"Serial Position\")\n",
      "#plt.ylabel(\"P(correct)\")\n",
      "#plt.title(\"Serial Position Effect\")\n",
      "#plt.subplot(2,1,2)\n",
      "#plt.plot(list(range(1,nsetsize)), transpos)\n",
      "#plt.xlabel(\"Transposition Distance\")\n",
      "#plt.ylabel(\"P(Response)\")\n",
      "#plt.title(\"Transposition Gradient\")\n",
      "#plt.show()        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.save(\"wm_output\", output_matrix)\n",
      "# output_matrix = np.load(\"wm_output.npy\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "  \n",
      "mIOX = np.mean(np.mean(output_matrix, 0), 0)   #computing the mean matrix from all the trials and replications  \n",
      "rIOX = mIOX[:nsetsize,:]   #take out the last row for extralist intrusions\n",
      "spc = np.diag(rIOX)        #serial position curve\n",
      "\n",
      "#transpos = np.zeros((1,setsize-1))\n",
      "transpos = [None]*(nsetsize-1)\n",
      "\n",
      "for tr in range(1,nsetsize):\n",
      "    transpos[tr-1] = np.mean((np.diag(rIOX,tr) + np.diag(rIOX,-tr))/2)\n",
      "\n",
      "print \"output_matrix: \\n\", output_matrix      \n",
      "print \"mean output matrix: \\n\", mIOX\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=(12, 12));\n",
      "plt.subplot(2, 1, 1)\n",
      "plt.plot(list(range(1,nsetsize+1)), spc)\n",
      "plt.xlabel(\"Serial Position\")\n",
      "plt.ylabel(\"P(correct)\")\n",
      "plt.title(\"Serial Position Effect\")\n",
      "plt.subplot(2,1,2)\n",
      "plt.plot(list(range(1,nsetsize)), transpos)\n",
      "plt.xlabel(\"Transposition Distance\")\n",
      "plt.ylabel(\"P(Response)\")\n",
      "plt.title(\"Transposition Gradient\")\n",
      "plt.show()        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}